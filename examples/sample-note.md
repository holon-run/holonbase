# AI 对齐研究笔记

## 概述

AI 对齐（AI Alignment）是确保人工智能系统的行为符合人类价值观和意图的问题。

## 核心挑战

1. **价值学习**：如何让 AI 理解人类的真实价值观
2. **目标规范**：如何准确地将人类意图转化为 AI 目标
3. **鲁棒性**：如何确保 AI 在各种情况下都保持对齐

## 相关研究

- Inverse Reinforcement Learning
- Constitutional AI
- Debate and Amplification

## 参考资料

- Alignment Forum: https://www.alignmentforum.org/
- AI Safety Gridworlds (DeepMind)
- RLHF (Reinforcement Learning from Human Feedback)
